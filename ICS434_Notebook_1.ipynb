{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICS 434 Homework Assignment 1 \n",
    "\n",
    "# <font color=\"red\">Due: 11:59 PM on Wednesday, February 12</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission Instructions\n",
    "\n",
    "1. Name your notebook file with the following naming convention using your last and first name as presented in Laulima.\n",
    "    - [LastName][FirstName]_[AssignmentNumber].ipynb\n",
    "    - For example, Bruce Wayne ==> WayneBruce_1.ipynb (The number at the end is the assignment number.)\n",
    "2. Only use .ipynb file extension. Other extensions (file formats) like .rtf, .zip, .docs, .pdf are not accepted.\n",
    "4. Never compress your files in a zip file. Data files are available to the instructor and the TA, so no need to upload them to Laulima. Make sure you use the same filenames of data files as given in the homework.\n",
    "5. Save data files in **\"data\" folder under your working directory**. Use **relative path** when you read in data in your code.\n",
    "6. Do not create any subfolders in your Drop Box.\n",
    "7. **Do NOT modify or delete the provided code.**\n",
    "8. Clean your code before submission.\n",
    "    - If needed, provide clear documentation describing the purpose and how to use every class or function in your code.\n",
    "    - Your submission **should show only the required outputs**. \n",
    "9. Run your code before submission to **show all outputs in the submitted file**. \n",
    "10. Write your full name in the cell below.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Your Name:\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview \n",
    "\n",
    "- The goal of this assignment is to practice some important data wrangling functionality commonly required in real-world projects.\n",
    "\n",
    "- Here we will use two datasets:\n",
    "  - IRS Statistics of Income (SOI) dataset\n",
    "  - The Medicaid Data per State  \n",
    "\n",
    "\n",
    "- The final product of this assignment is a table with medication cost per Medicaid enrollee per state. The Medicaid dataset will allow us to answer questions such as:\n",
    "  - Which medications account for the bulk of a state's spending   \n",
    "  - Which drugs are prescribed much more in one state compared to the other states.\n",
    "etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions on answering the questions\n",
    "\n",
    "- Some of the questions below require that you only use methods or properties of a `DataFrame` or a `Series`. Therefore, any solution that uses a function that is not a method or property of `DataFrame` or `Series` will not be accepted, even when the solution yields an appropriate answer to the question.\n",
    "\n",
    "- For instance, if you are asked to find the number of entries in the DataFrame `tax_data` using only the DataFrame's methods or properties, then `len(tax_data)` is not an acceptable solution since `len()` is not a `tax_data` method. The statements below are both correct answers:\n",
    "\n",
    "> - `info()` is a method of `tax_data`.\n",
    "  \n",
    "```python\n",
    "        tax_data.info()\n",
    "```\n",
    "\n",
    "&emsp;&emsp; or\n",
    "\n",
    "> - `shape` is a property of `tax_data`.\n",
    "\n",
    "```python\n",
    "        tax_data.shape\n",
    "```\n",
    "\n",
    "- Similarly, if you are asked to count the number of unique entries in the `STATEFIPS` column of the `tax_data` DataFrame, then solutions using `set()` or `len()` are not acceptable for the following reasons:\n",
    "\n",
    "> - The solution below uses `set()` and `len()`, which are not `tax_data` methods.\n",
    "\n",
    "```python\n",
    "        len(set(tax_data[\"STATEFIPS\"]))\n",
    "```\n",
    " \n",
    "> - The solution below uses `unique()`, which is a  `tax_data` method, but then counts the number of unique entries using `len()` which is not `tax_data` method.\n",
    "\n",
    "```python\n",
    "        len(tax_data[\"STATEFIPS\"].unique())\n",
    "```\n",
    "\n",
    "\n",
    "- The statement below is an acceptable solution since it uses `nunique()` which is a method of the `Series` generated by indexing on a column of `tax_data` (tax_data[\"STATEFIPS\"]).\n",
    "\n",
    "```python\n",
    "    tax_data['STATEFIPS'].nunique()\n",
    "```\n",
    "\n",
    "\n",
    "- Chaining methods and properties is encouraged if it does not cause ambiguity.\n",
    "\n",
    "- For instance, to identify whether a value is part of the index, write the following:\n",
    "\n",
    "```python\n",
    "    tax_data.index.contains(99999)\n",
    "```\n",
    "\n",
    "&emsp;&emsp; rather than:\n",
    "\n",
    "```python\n",
    "    9999 in tax_data.index\n",
    "```\n",
    "\n",
    "- You can only import `pandas` and `numpy`.\n",
    "\n",
    "- If you are not explicitely asked to only use methods or properties of a `DataFrame` or a `Series`, then any solution that does not rely on external products will be accepted.\n",
    "\n",
    "- __IMPORTANT__: Provide the exact statement(s) used to answer each question.\n",
    "\n",
    "- Unless otherwise specified, each cell can contain multiple lines of code.\n",
    "\n",
    "* Finally, note that not all the functions necessary for answering the questions below were covered in class. As such, I suggest you use `.SHIFT+TAB` or `.TAB` on objects liberally to see which methods and properties are available on objects. If you are unsure what a method does, use `SHIFT+TAB` to invoke the `docstring`, or documentation for that function. This is not only a good way to see which functionality can be used to answer the questions below but also a great way to familiarize yourself with the plethora of functionality available through the `pandas` package.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with the Tax Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Loading and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Load the IRS Statistics of Income (SOI) dataset (`tax_data.csv`) into a DataFrame called `tax_data`. The file is located in the `data` directory of the assignment folder.\n",
    "\n",
    "* This dataset was preprocessed but the original one was obtained at the following URL:\n",
    "\n",
    "        https://www.irs.gov/pub/irs-soi/15zpallagi.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a `tax_data` method or property to display the first eight (8) rows of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Modify `tax_data` to uppercase all the header names. \n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties.\n",
    "  * Do not hardcode the operation by uppercasing the column names yourself.\n",
    "  * You can use `tax_data.columns`, which returns a `Series` of the column names.\n",
    "  \n",
    "* The resulting column names should look as follows:\n",
    "\n",
    "\n",
    "```\n",
    "STATEFIPS    STATE    ZIPCODE    AGI_STUB    N1    MARS1    MARS2    MARS4    PREP    N2    ...    \n",
    "```\n",
    "\n",
    "* This operation is useful for standardizing column names and avoid guessing whether the column header was in upper case, lower case, or a mix of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the total number of entries (also called observations) in `tax_data`?\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `STATEFIPS` is header label of the first column (index 0) of the `tax_data` DataFrame, what is the label of the 32nd column?\n",
    "  - You should use a single python expression.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If `STATEFIPS` is the first column label (index 0), what is the index of the column labeled `N10300`?\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the count of unique zip codes in each state using descending order.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties.\n",
    "\n",
    "- The result should look like the following. ( '...' represents remaining data that is not shown here.)\n",
    "\n",
    "```python\n",
    "        ZIPCODE\n",
    "STATE\t\n",
    "TX\t     1619\n",
    "NY\t     1540\n",
    "CA\t     1485\n",
    "PA\t     1368\n",
    "IL\t     1231\n",
    "...\n",
    "```\n",
    "\n",
    "* The above indicates that there are 1,619 unique zip codes in TX, 1,540 in NY, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify the position of `HI` in the list of zip code counts per state generated in the previous question.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Identifying and removing entries with ambiguous zip codes\n",
    "\n",
    "- Count and print the number of entries in `tax_data` where ZIPCODE is 0. Assign your results to a variable named  `nb_invalid_zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to make sure that `nb_invalid_zip` is an integer (`int`).\n",
    "  * Note that `assert` will only print an error if `type(nb_invalid_zip)` is not of type `int`.\n",
    "  \n",
    "* If the code cell below returns an error, then change your answer above so that the value returned is effectively an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(type(nb_invalid_zip) == int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove from `tax_data` all the lines where the zip code is `0` and save resulting `DataFrame` to a variable named `tax_data_valid_zip`.\n",
    "  - Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected.\n",
    "\n",
    "  * The assertion below verifies that `nb_invalid_zip` + number of rows in `tax_data_valid_zip` is equal to the number of rows in the original DataFrame `tax_data`.\n",
    "  \n",
    "  * The assertion below will fail (and print an error message) if the results do not match. If that is the case, please review your code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip.shape[0] + nb_invalid_zip) == tax_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Identifying and removing entries with missing values\n",
    "\n",
    "* How many rows in the `tax_data_valid_zip` DataFrame contain at least one missing value (`NaN`) ?\n",
    "  * Your answer can only use `DataFrame` methods and properties.\n",
    "  \n",
    "* Assign the count of such rows to a variable called `nb_missing_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new `DataFrame` containing all the lines from `tax_data_valid_zip`, except lines containing missing values.\n",
    "\n",
    "  * Call the new `DataFrame` `tax_data_valid_zip_cleaned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the line below to confirm that the operation worked as expected. The assertion below tests that:  \n",
    "`nb_missing_values` + number of rows in `tax_data_valid_zip_cleaned` is equal to the number of rows in `tax_data_valid_zip`.\n",
    "  \n",
    "* Note that `assert` will only print an error if the results do not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((tax_data_valid_zip_cleaned.shape[0] + nb_missing_values) == tax_data_valid_zip.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Computing the percentile income per zip code\n",
    "\n",
    "* The function `compute_percentile_zip` below computes the percentile income per zip code.\n",
    "  * `N1` column: Number of tax returns\n",
    "  * `A00100` column: Adjusted gross income (AGI)\n",
    "\n",
    "\n",
    "* By default `percentile=0.5`,  i.e., the function computes the median.\n",
    "\n",
    "* Read the code and make sure you understand what it does before moving on to the next question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentile_zip(df_zip, percentile=0.5):     \n",
    "    index_median = sum((df_zip[\"N1\"] / sum(df_zip[\"N1\"])).cumsum() <= percentile)\n",
    "    val_below_or_at_median = (df_zip[\"A00100\"] / df_zip[\"N1\"]).iloc[index_median]\n",
    "    return val_below_or_at_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the 65th income percentile (percentile=0.65) for each zip code in `tax_data_valid_zip_cleaned` DataFrame.\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties.\n",
    "  \n",
    "  * Recall that you can use the `apply` function to transform the values of a column.\n",
    "  \n",
    "  \n",
    "* Sort the values in descending order and assign them to a variable named `zip_rev_all`.\n",
    "* The resulting `Series` should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "```Python\n",
    "ZIPCODE\n",
    "33109.0    3954.114286\n",
    "33480.0    3413.3015383\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the five zip codes with the most significant 65th percentile value for income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Working with the Medicaid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Loading and exploring the data \n",
    "\n",
    "* Load the Medicaid data stored in the file `medicaid_data.csv` into a DataFrame called `medicaid_data`. The file is located in the `data` directory of the assignment folder. \n",
    "\n",
    "* Note that this file is quite large and may take some time to load on a computer with modest RAM resources (e.g., 4GB or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Modify `medicaid_data` to capitalize all the column names.\n",
    "\n",
    "  - If your solution uses an assignment, the righthand side of the assignment (rvalue) can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Familiarize yourself with the data.\n",
    "  - The `NDC` column stands for National Drug Code, a universal product identifier for human drugs in the United States.\n",
    "  \n",
    "  - The remaining column names are self-explanatory.\n",
    "  \n",
    "  \n",
    "- Explore the number of rows and columns in the data.\n",
    "\n",
    "- Check that your column names are capitalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you explore the  `LOCATION` column for all the entries for which `STATE` value is equal to \"HI\" you'll notice that all the values are identical. Confirm it.\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Are there any states that have more than one unique value for `LOCATION`? If there are, list those states.\n",
    "  * This question can be answered by using aggregation and the Split-Apply-Combine paradigm.\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* To compare medication prescriptions across states in a fair and balanced way, we need the number of Medicaid beneficiaries in each state. That is, we need to compare per capita. The following example illustrates the importance of normalizing the values `UNITS REIMBURSED` for each medication in each state by the number of Medicaid enrollees in each state.\n",
    "  \n",
    "> The `medicaid_data` DataFrame shows that for the drug with NDC `61958180101` (the drug name is HARVONI and it's used to treat Hepatitis C) there were 11,886  units sold in KY, versus 40,142 in CA -- that's almost 4 times more units sold in CA compared to KY. However, there are 1,284,193 Medicaid enrollees in KY, versus 13,096,861 in California. If we normalize the number of units sold in KY versus CA, we find that there were close to 3 times more HARVONI prescription in KY  than in CA. This is ___perhaps___ justified by the fact the KY had one of the highest rates of reported cases of Hepatitis C in the US in 2015 (2.7% in KY versus 0.2% in CA).\n",
    "\n",
    "    https://www.cdc.gov/hepatitis/statistics/2015surveillance/pdfs/2015hepsurveillancerpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of enrollees per state was obtained from [here](https://www.medicaid.gov/medicaid/managed-care/enrollment-report/index.html).\n",
    "\n",
    "\n",
    "* A parsed/processed version (`medicaid_enrollment.tsv`) can be found in the `data` directory of the assignment folder.\n",
    "* Use `pandas` to load the `medicaid_enrollmen.tsv` file into a DataFrame named `medicaid_enrollment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify `medicaid_enrollment` to capitalize all the column names.\n",
    "\n",
    "  * Your answer can only use `DataFrame` or `Series` methods or properties.\n",
    "  * Do not hardcode the operation by manually uppercasing the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that some states/territories have missing values. Remove the entries with missing values and save the resulting DataFrame as a new variable named `medicaid_enrollment_cleaned`.\n",
    "\n",
    "* Pay attention to how 'n/a' is given here!\n",
    "* After cleaning, do you still have the Guam entry? If so, reconsider what missing values means in this context.\n",
    "    * Inspect the n/a values in `medicaid_enrollmen.tsv` file, and modify your code -- either here or the part reading in the file -- to make sure that the Guam entry doesn't appear after you remove the entries with missing values.\n",
    "    * Do not hardcode it by manually deleting the Guam entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Converting `TOTAL MEDICAID ENROLLEES` data type\n",
    "\n",
    "* Given that data on `TOTAL MEDICAID ENROLLEES` column contains commas on file (ex. 3,269,999 instead of 3269999), `pandas` has erroneously set the data type for that column as `object`. We need to convert the column from `object` to `int` since we will be using it in an arithmetic expression during normalization.\n",
    "\n",
    "\n",
    "* Convert the data type of `TOTAL MEDICAID ENROLLEES` column in `medicaid_enrollment_cleaned` to `int`. \n",
    "* Inspect the `dtype` property of the column, and  make sure that the data type is `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Associating `medicaid_data` and `medicaid_enrollment_cleaned`\n",
    "\n",
    "- We can use the shared State information across both tables to associate both tables (like SQL join).\n",
    "- However, `medicaid_data` contains two-letter state abbreviations, while `medicaid_enrollment_cleaned` contains the complete state name.\n",
    "  - We need to convert (or append) two-letter state abbreviations to `medicaid_enrollment_cleaned`.\n",
    "\n",
    "\n",
    "- Pandas can read HTML and parse the code for tables. We will use that functionality to read in the state abbreviations from a web page.\n",
    "  - A brief description of what the code does is included in the comments.\n",
    "  \n",
    "  \n",
    "- Note that the code below may throw an error if `lxml` is not installed on your machine. You should install any Python packages that Python complains about before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads all the tables at the given url.\n",
    "# Header=0 instructs pandas to use line 0 as the header (columns)\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = requests.get('https://www.50states.com/abbreviations.htm')\n",
    "tables = pd.read_html(StringIO(url.text), header=0)\n",
    "\n",
    "\n",
    "# We access the desired table by giving its index.\n",
    "# Since the URL contains three tables, we can access state abbreviations table using index 0.\n",
    "Codes_abbreviations = tables[0]\n",
    "Codes_abbreviations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the the `DataFrame`'s headers from ['US STATE',\t'POSTAL ABBREVIATION', \t'STANDARD ABBREVIATION'] to ['US STATE', 'ABBREVIATION', 'STD ABBREVIATION']\n",
    "\n",
    "  * You can hardcode this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combine the tables `medicaid_enrollment_cleaned` and `Codes_abbreviations` such that the resulting DataFrame contains all the columns in `medicaid_enrollment_cleaned` and only `ABBREVIATION` from `Codes_abbreviations`.\n",
    "  * Use the **default option (`inner`)** to merge.\n",
    "  * The resulting DataFrame should contain 50 entries.\n",
    "\n",
    "* Save the results to a variable named `medicaid_enrollment_cleaned_with_zip`.\n",
    "\n",
    "* `medicaid_enrollment_cleaned_with_zip` should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "\n",
    "```\n",
    "        STATE   TOTAL MEDICAID ENROLLEES   ABBREVIATION\n",
    "0     Alabama                    1050989             AL\n",
    "1      Alaska                     164783             AK\n",
    "2     Arizona                    1740520             AZ\n",
    "3    Arkansas                     762166             AR\n",
    "4  California                   13096861             CA\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have no further use for the column STATE in  `medicaid_enrollment_cleaned_with_zip`.\n",
    "  * Remove the column. Make sure your data in `medicaid_enrollment_cleaned_with_zip` looks like the following  ( '...' represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "   TOTAL MEDICAID ENROLLEES   ABBREVIATION\n",
    "0                   1050989             AL\n",
    "1                    164783             AK\n",
    "2                   1740520             AZ\n",
    "3                    762166             AR\n",
    "4                  13096861             CA\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the DataFrame `medicaid_enrollment_cleaned_with_zip` to assign the appropriate number of Medicaid enrollees to each entry in the `medicaid_data`.\n",
    "\n",
    "  - I.e., instead of the 10 original columns, `medicaid_data` will now have an 11th column representing the `TOTAL MEDICAID ENROLLEES` according to the `STATE` value in the entry.\n",
    "  - Use the **default option (`inner`)** to merge.\n",
    "\n",
    "   \n",
    "- Save the resulting DataFrame into a new variable called `medicaid_data_w_enrollments`.\n",
    "- The resulting DataFrame should look like the following ( '...' represents remaining data that is not shown):\n",
    "\n",
    "```\n",
    "                                                           NON                  TOTAL\n",
    "  UTILIZATION                         PRODUCT  ...    MEDICAID               MEDICAID\n",
    "         TYPE  STATE          NDC        NAME           AMOUNT    LOCATION  ENROLLEES\n",
    "                                                    REIMBURSED\n",
    "0        MCOU     PA  55150023930  Dexamethas  ...        0.00    (40.5773,  2569232.0\n",
    "                                                                   -77.264)\n",
    "1        FFSU     NY     23917710  ALPHAGAN P  ...        0.00    (42.1497,  6281038.0\n",
    "                                                                  -74.9384)\n",
    "2        MCOU     OR  13925050501  Dapsone 10  ...        0.00    (44.5672,  1123913.0\n",
    "                                                                 -122.1269)      \n",
    "...\n",
    "```\n",
    "\n",
    "* The order of the columns in the DataFrame is not important. This answer uses the same approach as the one used to `merge` the tables above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove any rows where `STATE` or `PRODUCT NAME` are missing from  `medicaid_data_w_enrollments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `[\"STATE\", \"NDC\"]` as hierarchical index for `medicaid_data_w_enrollments`. Recall that a hierarchical index is simply an index with multiple levels of indexing (multiple columns).\n",
    "  * Hint: The function to set an index on a DataFrame can take a single column name or a list of column names. The list here is `[\"STATE\", \"NDC\"]`.\n",
    "  \n",
    "  \n",
    "- Call the new data `medicaid_data_w_enrollments_hierarch`.\n",
    "\n",
    "\n",
    "- Inspect your data to make sure the new index has now two levels (STATE and NDC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Write a single Pandas expression to show all the rows containing `NDC` `61958180101` in the Pennsylvania (\"PA\").\n",
    "\n",
    " * Use a single indexing call (bracket notation) using `loc`.\n",
    " \n",
    " * Hint: Since your index is hierarchical, `loc` is expecting two values, the first for `STATE` and the second for `NDC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Computing the normalized `UNITS REIMBURSED` per enrollee\n",
    "\n",
    "* Compute the `UNITS REIMBURSED` for each \"NDC\" in each state normalized by the number of enrollees.\n",
    "\n",
    "\n",
    "> - For instance in `PA`, the total `UNITS REIMBURSED` for the HARVONI `NDC` (61958180101) is 10,612.\n",
    "\n",
    "```python\n",
    "      total_amount_reimbursed = medicaid_data_w_enrollments_hierarch.loc[(\"PA\", 61958180101), \"UNITS REIMBURSED\"].sum() \n",
    "```\n",
    "\n",
    "> - And the numebr of Medicaid Enrollees in \"PA\" is 2,569,232.\n",
    "\n",
    "```python\n",
    "      total_enrollees_PA = medicaid_data_w_enrollments_hierarch.loc[\"PA\", \"TOTAL MEDICAID ENROLLEES\"].unique()[0]\n",
    "```\n",
    "\n",
    "> - Therefore, the `UNITS REIMBURSED` per enrollee for \"HARVONI\" is  0.00413041718303.\n",
    "\n",
    "```python\n",
    "      print(total_amount_reimbursed/total_enrollees_PA)\n",
    "```\n",
    "\n",
    "- Rather than work directly with the ratios, we are going to compute and work with their logarithm (`np.log2`) instead.\n",
    "\n",
    "  - The reason we use logs here is to avoid working small numbers. More on log-transformation in future lectures.\n",
    "  \n",
    "\n",
    "- Save the result in a `Series` called `medicaid_reimbursement_per_enrollee`.\n",
    "\n",
    "\n",
    "- Your final result should be a `Series` that look like the following ( '...' represents data that is not shown here):\n",
    "\n",
    "  - Note that negative values are the result of the `log` transformation.\n",
    "  \n",
    "```\n",
    "STATE  NDC    \n",
    "AK     2143380    -9.609109\n",
    "       2143480   -10.008280\n",
    "       2322730    -6.109830\n",
    "       2322830    -4.444321\n",
    "       2322930    -3.855995\n",
    "...\n",
    "\n",
    "AL     2143380    -9.940595\n",
    "       2143480    -9.805485\n",
    "       2322730    -5.336260\n",
    "       2322830    -4.243688\n",
    "       2322930    -3.645575\n",
    "\n",
    "...\n",
    "\n",
    "MA     2143380    -7.921997\n",
    "       2143480    -7.803463\n",
    "       2144511   -13.472194\n",
    "       2197590    -7.741402\n",
    "       2322730    -5.414724\n",
    "       2322830    -4.592154\n",
    "       2322930    -4.205626\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To facilitate working with the final data, we are going to unstack `medicaid_reimbursement_per_enrollee` into a variable called  `medicaid_norm_ndc`.\n",
    "\n",
    "\n",
    "- Using `medicaid_reimbursement_per_enrollee`, generate a DataFrame where: \n",
    "  - index should be the two-letter state symbol \n",
    "  - column names are the `NDC` codes \n",
    "\n",
    "\n",
    "- The DataFrame should look like the following ('...' represents data that is not shown):\n",
    "  - Hint: Simply unstack the data.\n",
    "  \n",
    "  \n",
    "```\n",
    "  NDC    2143380     2143480     2144511 2144527    2197590    2322730 ... 99207026012 99207046330\n",
    "STATE\n",
    "   AK  -9.609109  -10.008280         NaN     NaN        NaN  -6.109830 ...         NaN         NaN\n",
    "   AL  -9.940595   -9.805485         NaN     NaN        NaN  -5.336260 ...         NaN         NaN\n",
    "   AR -12.985157  -12.657103         NaN     NaN        NaN  -4.720964 ...         NaN         NaN\n",
    "   AZ -11.533870  -10.821194         NaN     NaN        NaN  -5.312806 ...         NaN         NaN\n",
    "   CA -10.926863  -10.698372  -16.127018     NaN  -9.464364  -7.429936 ...         NaN  -15.150865\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Exploring the data (very briefly)\n",
    "- What is the NDC for the drug with the highest log-normalized ratio in Hawaii?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Investigate the NDC of the product with the highest log-normalized ratio in Hawaii.\n",
    "  * What is the name of the product? What is it used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WRITE YOUR ANSWER HERE:**\n",
    ">\n",
    "> \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compare the log-normalized `UNITS REIMBURSED` per enrollee of that product between HI and other states, (take for instance MA, FL, OR and WA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WRITE YOUR CODE HERE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you think for reasons why this product has the highest log-normalized ratio in Hawaii? (Not graded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **WRITE YOUR ANSWER HERE**\n",
    "> \n",
    "> "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
